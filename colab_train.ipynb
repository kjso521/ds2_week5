{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# ì‚¼ì„± DS ê³¼ì œ - DnCNN ëª¨ë¸ í•™ìŠµ íŒŒì´í”„ë¼ì¸ (On-the-fly Augmentation Ver.)\n",
        "\n",
        "ì´ ë…¸íŠ¸ë¶ì€ \"On-the-fly Augmentation\" ë°©ì‹ì„ ì‚¬ìš©í•˜ì—¬ Denoising, Deconvolution, End-to-End ëª¨ë¸ì„ í•™ìŠµì‹œí‚¤ëŠ” íŒŒì´í”„ë¼ì¸ì…ë‹ˆë‹¤.\n",
        "\n",
        "**ì£¼ìš” íŠ¹ì§•:**\n",
        "- **ì‹¤ì‹œê°„ ë°ì´í„° ì¦ê°•:** ëŒ€ìš©ëŸ‰ ë°ì´í„°ì…‹ì„ ë¯¸ë¦¬ ìƒì„±í•  í•„ìš” ì—†ì´, í•™ìŠµ ì¤‘ì— ì‹¤ì‹œê°„ìœ¼ë¡œ ì›ë³¸ ì´ë¯¸ì§€ì— ì†ìƒ(Noise, Convolution)ì„ ì ìš©í•©ë‹ˆë‹¤. ì´ë¥¼ í†µí•´ I/O ë³‘ëª© í˜„ìƒì„ í•´ê²°í•˜ê³  ì €ì¥ ê³µê°„ì„ ì ˆì•½í•©ë‹ˆë‹¤.\n",
        "- **í†µí•© í™˜ê²½:** Denoising, Deconvolution, End-to-End ì„¸ ê°€ì§€ ì‹¤í—˜ì„ ë…¸íŠ¸ë¶ ì…€ ì„ íƒì„ í†µí•´ ê°„ë‹¨í•˜ê²Œ ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "- **ë¡œì»¬ í™˜ê²½ í˜¸í™˜:** `params.py`ì— í™˜ê²½ ìë™ ê°ì§€ ê¸°ëŠ¥ì´ ì¶”ê°€ë˜ì–´, ì´ ë…¸íŠ¸ë¶ê³¼ ë™ì¼í•œ ì½”ë“œë¥¼ ë¡œì»¬ Windows í™˜ê²½ì—ì„œë„ (CPUë¡œ) ì‹¤í–‰í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.\n",
        "\n",
        "**ì‹¤í–‰ ìˆœì„œ:**\n",
        "1. **1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„:** Drive ë§ˆìš´íŠ¸, ê²½ë¡œ ì„¤ì •, ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜ ë° ì›ë³¸ ë°ì´í„°ì…‹(train, val)ì„ Colab ë¡œì»¬ ëŸ°íƒ€ì„ìœ¼ë¡œ ë³µì‚¬í•©ë‹ˆë‹¤. (ìµœì´ˆ 1íšŒ í•„ìˆ˜ ì‹¤í–‰)\n",
        "2. **2. í•™ìŠµ ì‹¤í–‰:** ì›í•˜ëŠ” ì‹¤í—˜(Denoising, Deconvolution, End-to-End)ì— í•´ë‹¹í•˜ëŠ” ì…€ì„ ì„ íƒí•˜ì—¬ ì‹¤í–‰í•©ë‹ˆë‹¤. \n",
        "   - ë¡œê·¸ì™€ í•™ìŠµëœ ëª¨ë¸(`.ckpt`), í…ŒìŠ¤íŠ¸ ê²°ê³¼ë¬¼ì€ ëª¨ë‘ Google Driveì˜ í”„ë¡œì íŠ¸ í´ë” ë‚´ `logs_...` ë””ë ‰í† ë¦¬ì— ì €ì¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. í™˜ê²½ ì„¤ì • ë° ë°ì´í„° ì¤€ë¹„\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title Google Drive ë§ˆìš´íŠ¸\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title í”„ë¡œì íŠ¸ ê²½ë¡œ ì„¤ì • ë° ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# ğŸ’¥ ì‚¬ìš©ì ì„¤ì •: ìì‹ ì˜ Google Drive í”„ë¡œì íŠ¸ ê²½ë¡œì— ë§ê²Œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.\n",
        "PROJECT_ROOT = \"/content/drive/MyDrive/Data Scientist/Project/Week5/week5\"\n",
        "os.chdir(PROJECT_ROOT)\n",
        "sys.path.append(PROJECT_ROOT)\n",
        "\n",
        "print(f\"Current working directory: {os.getcwd()}\")\n",
        "\n",
        "# í•„ìš”í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„¤ì¹˜\n",
        "%pip install loguru tqdm --quiet\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸš€ [í•„ìˆ˜] ì›ë³¸ ë°ì´í„°ì…‹ ë¡œì»¬ ëŸ°íƒ€ì„ìœ¼ë¡œ ë³µì‚¬\n",
        "import shutil\n",
        "from pathlib import Path\n",
        "from tqdm.notebook import tqdm\n",
        "\n",
        "DRIVE_DATASET_ROOT = Path(PROJECT_ROOT) / \"dataset\"\n",
        "LOCAL_DATASET_ROOT = Path(\"/content/dataset\")\n",
        "\n",
        "# ë³µì‚¬í•  í´ë” ëª©ë¡ (ì›ë³¸ ë°ì´í„°ë§Œ)\n",
        "folders_to_copy = [\"train\", \"val\"]\n",
        "\n",
        "print(\"Starting dataset copy from Google Drive to local runtime...\")\n",
        "\n",
        "if LOCAL_DATASET_ROOT.exists():\n",
        "    print(\"Local dataset folder already exists. Skipping copy.\")\n",
        "else:\n",
        "    LOCAL_DATASET_ROOT.mkdir(parents=True, exist_ok=True)\n",
        "    \n",
        "    total_files = 0\n",
        "    for folder in folders_to_copy:\n",
        "        source_folder = DRIVE_DATASET_ROOT / folder\n",
        "        if source_folder.exists():\n",
        "            # ì „ì²´ íŒŒì¼ ìˆ˜ ê³„ì‚°\n",
        "            total_files += len(list(source_folder.glob('**/*')))\n",
        "\n",
        "    with tqdm(total=total_files, unit=\"file\") as pbar:\n",
        "        for folder in folders_to_copy:\n",
        "            source_folder = DRIVE_DATASET_ROOT / folder\n",
        "            target_folder = LOCAL_DATASET_ROOT / folder\n",
        "            \n",
        "            if not source_folder.exists():\n",
        "                print(f\"Warning: Source folder '{source_folder}' not found in Drive.\")\n",
        "                continue\n",
        "                \n",
        "            if not target_folder.exists():\n",
        "                target_folder.mkdir(parents=True)\n",
        "            \n",
        "            pbar.set_description(f\"Copying {folder}...\")\n",
        "            for file_path in source_folder.glob('**/*'):\n",
        "                if file_path.is_file():\n",
        "                    shutil.copy(file_path, target_folder / file_path.name)\n",
        "                    pbar.update(1)\n",
        "\n",
        "    print(\"\\nDataset copy finished!\")\n",
        "\n",
        "# params.pyê°€ ë¡œì»¬ ê²½ë¡œë¥¼ ë°”ë¼ë³´ë„ë¡ í™˜ê²½ ë³€ìˆ˜ ì„¤ì •\n",
        "os.environ['DATA_ROOT'] = str(LOCAL_DATASET_ROOT)\n",
        "print(f\"DATA_ROOT is now set to: {os.environ.get('DATA_ROOT')}\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. í•™ìŠµ ì‹¤í–‰\n",
        "\n",
        "ì•„ë˜ 3ê°œì˜ ì…€ ì¤‘ ì›í•˜ëŠ” ì‹¤í—˜ì„ ì„ íƒí•˜ì—¬ ì‹¤í–‰í•˜ì„¸ìš”. ë¡œê·¸ì™€ ê²°ê³¼ë¬¼ì€ Driveì— ì €ì¥ë©ë‹ˆë‹¤.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ§ª 1. Denoising ëª¨ë¸ í•™ìŠµ (Noise Only)\n",
        "!python ./code_denoising/train.py --run_dir_name \"logs_denoising\" --augmentation_mode \"noise_only\" --train_epoch 100 --train_batch 4 --valid_batch 8 --num_workers 4 --lr 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# @title ğŸ§ª 2. Deconvolution ëª¨ë¸ í•™ìŠµ (Convolution Only)\n",
        "!python ./code_denoising/train.py --run_dir_name \"logs_deconvolution\" --augmentation_mode \"conv_only\" --train_epoch 100 --train_batch 4 --valid_batch 8 --num_workers 4 --lr 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "^C\n"
          ]
        }
      ],
      "source": [
        "# @title ğŸ§ª 3. End-to-End ëª¨ë¸ í•™ìŠµ (Noise + Convolution)\n",
        "!python ./code_denoising/train.py --run_dir_name \"logs_end_to_end\" --augmentation_mode \"both\" --train_epoch 100 --train_batch 4 --valid_batch 8 --num_workers 4 --lr 1e-4\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
